<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Lambda on Scott Obert</title><link>https://scottobert.github.io/tags/lambda/</link><description>Recent content in Lambda on Scott Obert</description><generator>Hugo</generator><language>en</language><copyright>&amp;copy;2022 Scott Obert</copyright><lastBuildDate>Sat, 17 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://scottobert.github.io/tags/lambda/index.xml" rel="self" type="application/rss+xml"/><item><title>Cost Optimization Strategies for AWS Serverless Applications</title><link>https://scottobert.github.io/posts/aws-serverless-cost-optimization/</link><pubDate>Sat, 17 Jun 2023 00:00:00 +0000</pubDate><guid>https://scottobert.github.io/posts/aws-serverless-cost-optimization/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>While serverless architectures can significantly reduce operational costs, they require thoughtful design and configuration to maximize cost efficiency. This guide explores practical strategies for optimizing costs in AWS serverless applications, based on real-world experience and proven patterns.&lt;/p>
&lt;h2 id="lambda-function-optimization">Lambda Function Optimization&lt;/h2>
&lt;h3 id="memory-and-duration-trade-offs">Memory and Duration Trade-offs&lt;/h3>
&lt;p>The relationship between Lambda memory allocation and execution duration isn&amp;rsquo;t always intuitive. Higher memory allocations often lead to faster execution times, potentially reducing overall costs. When right-sizing memory for your functions, start with the minimum required memory of 128MB and gradually increase while monitoring performance. In many cases, doubling the memory from 128MB to 256MB can cut execution time in half, resulting in lower overall costs despite the higher memory price.&lt;/p></description></item><item><title>Real-time Processing Architectures</title><link>https://scottobert.github.io/posts/real-time-processing-architectures/</link><pubDate>Sun, 11 Apr 2021 09:00:00 -0500</pubDate><guid>https://scottobert.github.io/posts/real-time-processing-architectures/</guid><description>&lt;p>Real-time processing architectures address the fundamental challenge of extracting actionable insights from continuously flowing data streams while maintaining low latency and high throughput requirements. Unlike batch processing systems that operate on static datasets with relaxed timing constraints, real-time systems must process events as they arrive, often within milliseconds or seconds of generation. This temporal sensitivity introduces unique design considerations around event ordering, backpressure handling, and state management that distinguish real-time architectures from their batch-oriented counterparts.&lt;/p></description></item><item><title>CQRS Implementation with AWS Services</title><link>https://scottobert.github.io/posts/cqrs-implementation-aws-services/</link><pubDate>Sun, 17 Jan 2021 09:00:00 -0500</pubDate><guid>https://scottobert.github.io/posts/cqrs-implementation-aws-services/</guid><description>&lt;p>Command Query Responsibility Segregation represents a fundamental shift in how we think about data persistence and retrieval in distributed systems. Rather than treating reads and writes as symmetric operations against a single data model, CQRS acknowledges the inherent differences between these operations and optimizes each path independently. In the context of AWS services, this pattern becomes particularly powerful when we leverage the managed services ecosystem to handle the complexity of maintaining separate command and query models.&lt;/p></description></item></channel></rss>